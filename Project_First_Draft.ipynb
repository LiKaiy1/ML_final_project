{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Draft Codes for Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import visuals as vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Unix</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>stock_p_change</th>\n",
       "      <th>SP500</th>\n",
       "      <th>SP500_p_change</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Trailing P/E</th>\n",
       "      <th>...</th>\n",
       "      <th>Avg Vol (3 month)</th>\n",
       "      <th>Shares Outstanding</th>\n",
       "      <th>Float</th>\n",
       "      <th>% Held by Insiders</th>\n",
       "      <th>% Held by Institutions</th>\n",
       "      <th>Shares Short (as of</th>\n",
       "      <th>Short Ratio</th>\n",
       "      <th>Short % of Float</th>\n",
       "      <th>Shares Short (prior month</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/30/04 19:01</td>\n",
       "      <td>1075460462</td>\n",
       "      <td>a</td>\n",
       "      <td>22.984629</td>\n",
       "      <td>-41.37</td>\n",
       "      <td>84.478371</td>\n",
       "      <td>5.46</td>\n",
       "      <td>1.745000e+10</td>\n",
       "      <td>1.652000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2989323.0</td>\n",
       "      <td>476150000.0</td>\n",
       "      <td>428500000.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>63.03</td>\n",
       "      <td>9300000.0</td>\n",
       "      <td>3.923</td>\n",
       "      <td>2.17</td>\n",
       "      <td>6930000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/13/04 4:07</td>\n",
       "      <td>1081800431</td>\n",
       "      <td>a</td>\n",
       "      <td>19.336773</td>\n",
       "      <td>-32.89</td>\n",
       "      <td>84.572807</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.532000e+10</td>\n",
       "      <td>1.477000e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3536636.0</td>\n",
       "      <td>480750000.0</td>\n",
       "      <td>432700000.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>66.79</td>\n",
       "      <td>7520000.0</td>\n",
       "      <td>2.328</td>\n",
       "      <td>1.74</td>\n",
       "      <td>9170000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/13/04 21:37</td>\n",
       "      <td>1102945054</td>\n",
       "      <td>a</td>\n",
       "      <td>14.865800</td>\n",
       "      <td>50.92</td>\n",
       "      <td>90.894150</td>\n",
       "      <td>7.57</td>\n",
       "      <td>1.161000e+10</td>\n",
       "      <td>1.037000e+10</td>\n",
       "      <td>33.58</td>\n",
       "      <td>...</td>\n",
       "      <td>2780227.0</td>\n",
       "      <td>487000000.0</td>\n",
       "      <td>389600000.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>66.68</td>\n",
       "      <td>6930000.0</td>\n",
       "      <td>2.638</td>\n",
       "      <td>1.78</td>\n",
       "      <td>6540000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/22/05 5:17</td>\n",
       "      <td>1106342239</td>\n",
       "      <td>a</td>\n",
       "      <td>13.593730</td>\n",
       "      <td>57.11</td>\n",
       "      <td>88.599785</td>\n",
       "      <td>9.77</td>\n",
       "      <td>1.071000e+10</td>\n",
       "      <td>9.760000e+09</td>\n",
       "      <td>30.70</td>\n",
       "      <td>...</td>\n",
       "      <td>2459863.0</td>\n",
       "      <td>491070000.0</td>\n",
       "      <td>441400000.0</td>\n",
       "      <td>10.12</td>\n",
       "      <td>67.08</td>\n",
       "      <td>7040000.0</td>\n",
       "      <td>2.385</td>\n",
       "      <td>1.60</td>\n",
       "      <td>6930000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/06 2:35</td>\n",
       "      <td>1136745316</td>\n",
       "      <td>a</td>\n",
       "      <td>21.544186</td>\n",
       "      <td>4.47</td>\n",
       "      <td>99.419518</td>\n",
       "      <td>11.58</td>\n",
       "      <td>1.712000e+10</td>\n",
       "      <td>1.487000e+10</td>\n",
       "      <td>52.82</td>\n",
       "      <td>...</td>\n",
       "      <td>3843670.0</td>\n",
       "      <td>494180000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57</td>\n",
       "      <td>70.40</td>\n",
       "      <td>10980000.0</td>\n",
       "      <td>2.300</td>\n",
       "      <td>2.20</td>\n",
       "      <td>5840000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Unix Ticker      Price  stock_p_change      SP500  \\\n",
       "0   1/30/04 19:01  1075460462      a  22.984629          -41.37  84.478371   \n",
       "1    4/13/04 4:07  1081800431      a  19.336773          -32.89  84.572807   \n",
       "2  12/13/04 21:37  1102945054      a  14.865800           50.92  90.894150   \n",
       "3    1/22/05 5:17  1106342239      a  13.593730           57.11  88.599785   \n",
       "4     1/9/06 2:35  1136745316      a  21.544186            4.47  99.419518   \n",
       "\n",
       "   SP500_p_change    Market Cap  Enterprise Value  Trailing P/E  ...    \\\n",
       "0            5.46  1.745000e+10      1.652000e+10           NaN  ...     \n",
       "1            5.64  1.532000e+10      1.477000e+10           NaN  ...     \n",
       "2            7.57  1.161000e+10      1.037000e+10         33.58  ...     \n",
       "3            9.77  1.071000e+10      9.760000e+09         30.70  ...     \n",
       "4           11.58  1.712000e+10      1.487000e+10         52.82  ...     \n",
       "\n",
       "   Avg Vol (3 month)  Shares Outstanding        Float  % Held by Insiders  \\\n",
       "0          2989323.0         476150000.0  428500000.0               10.01   \n",
       "1          3536636.0         480750000.0  432700000.0               10.00   \n",
       "2          2780227.0         487000000.0  389600000.0               20.00   \n",
       "3          2459863.0         491070000.0  441400000.0               10.12   \n",
       "4          3843670.0         494180000.0          NaN                0.57   \n",
       "\n",
       "   % Held by Institutions  Shares Short (as of  Short Ratio  Short % of Float  \\\n",
       "0                   63.03            9300000.0        3.923              2.17   \n",
       "1                   66.79            7520000.0        2.328              1.74   \n",
       "2                   66.68            6930000.0        2.638              1.78   \n",
       "3                   67.08            7040000.0        2.385              1.60   \n",
       "4                   70.40           10980000.0        2.300              2.20   \n",
       "\n",
       "   Shares Short (prior month  Label  \n",
       "0                  6930000.0    Yes  \n",
       "1                  9170000.0    Yes  \n",
       "2                  6540000.0    Yes  \n",
       "3                  6930000.0    Yes  \n",
       "4                  5840000.0    Yes  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readCSV():\n",
    "    raw_data = pd.read_csv('raw_data.csv')\n",
    "    return raw_data\n",
    "raw_data = readCSV()\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chose features in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Unix',\n",
       " 'Ticker',\n",
       " 'Price',\n",
       " 'stock_p_change',\n",
       " 'SP500',\n",
       " 'SP500_p_change',\n",
       " 'Market Cap',\n",
       " 'Enterprise Value',\n",
       " 'Trailing P/E',\n",
       " 'Forward P/E',\n",
       " 'PEG Ratio',\n",
       " 'Price/Sales',\n",
       " 'Price/Book',\n",
       " 'Enterprise Value/Revenue',\n",
       " 'Enterprise Value/EBITDA',\n",
       " 'Profit Margin',\n",
       " 'Operating Margin',\n",
       " 'Return on Assets',\n",
       " 'Return on Equity',\n",
       " 'Revenue',\n",
       " 'Revenue Per Share',\n",
       " 'Qtrly Revenue Growth',\n",
       " 'Gross Profit',\n",
       " 'EBITDA',\n",
       " 'Net Income Avl to Common',\n",
       " 'Diluted EPS',\n",
       " 'Qtrly Earnings Growth',\n",
       " 'Total Cash',\n",
       " 'Total Cash Per Share',\n",
       " 'Total Debt',\n",
       " 'Total Debt/Equity',\n",
       " 'Current Ratio',\n",
       " 'Book Value Per Share',\n",
       " 'Operating Cash Flow',\n",
       " 'Levered Free Cash Flow',\n",
       " 'Beta',\n",
       " '50-Day Moving Average',\n",
       " '200-Day Moving Average',\n",
       " 'Avg Vol (3 month)',\n",
       " 'Shares Outstanding',\n",
       " 'Float',\n",
       " '% Held by Insiders',\n",
       " '% Held by Institutions',\n",
       " 'Shares Short (as of',\n",
       " 'Short Ratio',\n",
       " 'Short % of Float',\n",
       " 'Shares Short (prior month',\n",
       " 'Label']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_names = list(raw_data)\n",
    "columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trailing P/E</th>\n",
       "      <th>Forward P/E</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Price/Sales</th>\n",
       "      <th>Price/Book</th>\n",
       "      <th>Enterprise Value/Revenue</th>\n",
       "      <th>Enterprise Value/EBITDA</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>Operating Margin</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>...</th>\n",
       "      <th>50-Day Moving Average</th>\n",
       "      <th>200-Day Moving Average</th>\n",
       "      <th>Avg Vol (3 month)</th>\n",
       "      <th>Shares Outstanding</th>\n",
       "      <th>% Held by Insiders</th>\n",
       "      <th>% Held by Institutions</th>\n",
       "      <th>Shares Short (as of</th>\n",
       "      <th>Short Ratio</th>\n",
       "      <th>Short % of Float</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25.83</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.80</td>\n",
       "      <td>6.01</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-29.56</td>\n",
       "      <td>-11.97</td>\n",
       "      <td>-24.95</td>\n",
       "      <td>...</td>\n",
       "      <td>29.47</td>\n",
       "      <td>23.24</td>\n",
       "      <td>2989323.0</td>\n",
       "      <td>476150000.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>63.03</td>\n",
       "      <td>9300000.0</td>\n",
       "      <td>3.923</td>\n",
       "      <td>2.17</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.83</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.43</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-25.56</td>\n",
       "      <td>-6.20</td>\n",
       "      <td>-23.59</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53</td>\n",
       "      <td>27.32</td>\n",
       "      <td>3536636.0</td>\n",
       "      <td>480750000.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>66.79</td>\n",
       "      <td>7520000.0</td>\n",
       "      <td>2.328</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.58</td>\n",
       "      <td>15.79</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.24</td>\n",
       "      <td>1.44</td>\n",
       "      <td>15.300</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.38</td>\n",
       "      <td>5.26</td>\n",
       "      <td>...</td>\n",
       "      <td>23.64</td>\n",
       "      <td>25.64</td>\n",
       "      <td>2780227.0</td>\n",
       "      <td>487000000.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>66.68</td>\n",
       "      <td>6930000.0</td>\n",
       "      <td>2.638</td>\n",
       "      <td>1.78</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.70</td>\n",
       "      <td>14.34</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.52</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.36</td>\n",
       "      <td>14.400</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.38</td>\n",
       "      <td>5.26</td>\n",
       "      <td>...</td>\n",
       "      <td>23.71</td>\n",
       "      <td>24.72</td>\n",
       "      <td>2459863.0</td>\n",
       "      <td>491070000.0</td>\n",
       "      <td>10.12</td>\n",
       "      <td>67.08</td>\n",
       "      <td>7040000.0</td>\n",
       "      <td>2.385</td>\n",
       "      <td>1.60</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.82</td>\n",
       "      <td>19.69</td>\n",
       "      <td>1.81</td>\n",
       "      <td>3.31</td>\n",
       "      <td>4.26</td>\n",
       "      <td>2.89</td>\n",
       "      <td>35.665</td>\n",
       "      <td>6.38</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.68</td>\n",
       "      <td>...</td>\n",
       "      <td>34.92</td>\n",
       "      <td>30.86</td>\n",
       "      <td>3843670.0</td>\n",
       "      <td>494180000.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>70.40</td>\n",
       "      <td>10980000.0</td>\n",
       "      <td>2.300</td>\n",
       "      <td>2.20</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trailing P/E  Forward P/E  PEG Ratio  Price/Sales  Price/Book  \\\n",
       "0           NaN        25.83       3.84         2.80        6.01   \n",
       "1           NaN        20.83       2.89         2.43        4.98   \n",
       "2         33.58        15.79       1.62         1.61        3.24   \n",
       "3         30.70        14.34       1.51         1.52        3.04   \n",
       "4         52.82        19.69       1.81         3.31        4.26   \n",
       "\n",
       "   Enterprise Value/Revenue  Enterprise Value/EBITDA  Profit Margin  \\\n",
       "0                      2.73                      NaN         -29.56   \n",
       "1                      2.35                      NaN         -25.56   \n",
       "2                      1.44                   15.300           4.86   \n",
       "3                      1.36                   14.400           4.86   \n",
       "4                      2.89                   35.665           6.38   \n",
       "\n",
       "   Operating Margin  Return on Assets  ...    50-Day Moving Average  \\\n",
       "0            -11.97            -24.95  ...                    29.47   \n",
       "1             -6.20            -23.59  ...                    33.53   \n",
       "2              5.38              5.26  ...                    23.64   \n",
       "3              5.38              5.26  ...                    23.71   \n",
       "4              3.58              1.68  ...                    34.92   \n",
       "\n",
       "   200-Day Moving Average  Avg Vol (3 month)  Shares Outstanding  \\\n",
       "0                   23.24          2989323.0         476150000.0   \n",
       "1                   27.32          3536636.0         480750000.0   \n",
       "2                   25.64          2780227.0         487000000.0   \n",
       "3                   24.72          2459863.0         491070000.0   \n",
       "4                   30.86          3843670.0         494180000.0   \n",
       "\n",
       "   % Held by Insiders  % Held by Institutions  Shares Short (as of  \\\n",
       "0               10.01                   63.03            9300000.0   \n",
       "1               10.00                   66.79            7520000.0   \n",
       "2               20.00                   66.68            6930000.0   \n",
       "3               10.12                   67.08            7040000.0   \n",
       "4                0.57                   70.40           10980000.0   \n",
       "\n",
       "   Short Ratio  Short % of Float  Label  \n",
       "0        3.923              2.17    Yes  \n",
       "1        2.328              1.74    Yes  \n",
       "2        2.638              1.78    Yes  \n",
       "3        2.385              1.60    Yes  \n",
       "4        2.300              2.20    Yes  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chose_features():\n",
    "    features = [\n",
    " 'Trailing P/E',\n",
    " 'Forward P/E',\n",
    " 'PEG Ratio',\n",
    " 'Price/Sales',\n",
    " 'Price/Book',\n",
    " 'Enterprise Value/Revenue',\n",
    " 'Enterprise Value/EBITDA',\n",
    " 'Profit Margin',\n",
    " 'Operating Margin',\n",
    " 'Return on Assets',\n",
    " 'Return on Equity',\n",
    " 'Revenue Per Share',\n",
    " 'Qtrly Revenue Growth', 'EBITDA',\n",
    " 'Net Income Avl to Common',\n",
    " 'Diluted EPS',\n",
    " 'Qtrly Earnings Growth',\n",
    " 'Total Cash',\n",
    " 'Total Cash Per Share',\n",
    " 'Total Debt',\n",
    " 'Total Debt/Equity',\n",
    " 'Current Ratio',\n",
    " 'Book Value Per Share',\n",
    " 'Operating Cash Flow',\n",
    " 'Levered Free Cash Flow',\n",
    " 'Beta',\n",
    " '50-Day Moving Average',\n",
    " '200-Day Moving Average',\n",
    " 'Avg Vol (3 month)',\n",
    " 'Shares Outstanding',\n",
    " '% Held by Insiders',\n",
    " '% Held by Institutions',\n",
    " 'Shares Short (as of',\n",
    " 'Short Ratio',\n",
    " 'Short % of Float','Label']\n",
    "    selected_columns_data = raw_data[features]\n",
    "    return features,selected_columns_data\n",
    "features,selected_columns_data = chose_features()\n",
    "selected_columns_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle *Missing Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_columns_data.isna()\n",
    "selected_columns_data = selected_columns_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Y matrix as the outperformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = selected_columns_data[features[-1]].values\n",
    "# Encode the label for score calculating later\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "Y = np.array([number[0] for number in lb.fit_transform(Y)])\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define X matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  5.08000000e+00,   1.73000000e+01,   1.26000000e+00, ...,\n",
       "           6.92000000e+06,   3.40000000e+00,   1.60000000e+00],\n",
       "        [  4.63000000e+00,   1.70100000e+01,   1.21000000e+00, ...,\n",
       "           7.35000000e+06,   2.50000000e+00,   1.80000000e+00],\n",
       "        [  4.33000000e+00,   1.51100000e+01,   1.13000000e+00, ...,\n",
       "           5.91000000e+06,   2.80000000e+00,   1.50000000e+00],\n",
       "        ..., \n",
       "        [  1.74800000e+01,   1.38600000e+01,   1.27000000e+00, ...,\n",
       "           4.30000000e+06,   2.90000000e+00,   2.70000000e+00],\n",
       "        [  1.75100000e+01,   1.38900000e+01,   1.29000000e+00, ...,\n",
       "           4.52000000e+06,   2.80000000e+00,   2.90000000e+00],\n",
       "        [  1.66200000e+01,   1.39600000e+01,   1.34000000e+00, ...,\n",
       "           5.67000000e+06,   3.90000000e+00,   4.10000000e+00]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.matrix(selected_columns_data[features[0:-1]].values)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  1.64600000e+01,   1.35400000e+01,   1.23000000e+00, ...,\n",
       "           1.26000000e+06,   1.80000000e+00,   1.30000000e+00],\n",
       "        [  1.49470000e+02,   2.98100000e+01,   1.13000000e+00, ...,\n",
       "           9.20000000e+06,   2.20000000e+00,   5.90000000e+00],\n",
       "        [  1.65300000e+01,   2.25400000e+01,   1.73000000e+00, ...,\n",
       "           6.26000000e+06,   3.00000000e+00,   1.10000000e+00],\n",
       "        ..., \n",
       "        [  5.82000000e+00,   1.56400000e+01,   7.20000000e-01, ...,\n",
       "           2.02800000e+07,   2.60000000e+00,   9.20000000e+00],\n",
       "        [  4.08400000e+01,   3.24600000e+01,   3.72000000e+00, ...,\n",
       "           5.67100000e+07,   6.60000000e+00,   4.20000000e+00],\n",
       "        [  1.60600000e+01,   1.38500000e+01,   1.05000000e+00, ...,\n",
       "           4.06500000e+07,   1.40000000e+00,   2.90000000e+00]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outperformered stocks: 1505\n",
      "Number of underperformered stocks: 303\n",
      "Total number of data points: 1808\n",
      "Percentage of outperformer stocks: 0.20132890365448505\n",
      "----------------------------------------------------------------------------\n",
      "Train Sample Size: 1446\n",
      "Test Sample Size: 362\n"
     ]
    }
   ],
   "source": [
    "def data_report(df):\n",
    "    no_good_df = df.loc[df['Label'] == 'No']\n",
    "    good_df = df.loc[df['Label'] == 'Yes']\n",
    "    print(\"Number of outperformered stocks: {}\".format(len(good_df)))\n",
    "    print(\"Number of underperformered stocks: {}\".format(len(no_good_df)))\n",
    "    print(\"Total number of data points: {}\".format(len(df)))\n",
    "    print(\"Percentage of outperformer stocks: {}\".format(len(no_good_df)/len(good_df)))\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    print(\"Train Sample Size: {}\".format(len(X_train)))\n",
    "    print(\"Test Sample Size: {}\".format(len(X_test)))\n",
    "data_report(selected_columns_data)\n",
    "# data_report(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *MinMax Scaler*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.26501347e-02,   2.70194986e-01,   3.36953771e-01, ...,\n",
       "          2.45820571e-01,   2.38461538e-01,   8.83002208e-02],\n",
       "       [  8.81540485e-03,   1.33530641e-01,   3.37936740e-01, ...,\n",
       "          4.51136422e-02,   2.23076923e-01,   7.72626932e-02],\n",
       "       [  6.68477605e-03,   9.22701950e-02,   3.34102190e-01, ...,\n",
       "          2.39490180e-03,   1.15384615e-02,   1.10375276e-02],\n",
       "       ..., \n",
       "       [  6.72497660e-03,   9.75800836e-02,   3.34277372e-01, ...,\n",
       "          3.73840673e-02,   1.96153846e-01,   1.89845475e-01],\n",
       "       [  2.34311738e-03,   4.19568245e-02,   3.33800487e-01, ...,\n",
       "          8.25387592e-02,   6.92307692e-02,   6.62251656e-02],\n",
       "       [  5.22607063e-04,   4.79630919e-02,   3.34092457e-01, ...,\n",
       "          6.01948726e-01,   1.26923077e-01,   8.83002208e-02]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minmax_scale(X):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X\n",
    "X_train,X_test = minmax_scale(X_train),minmax_scale(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Robust scaler*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18203088,  0.17231284, -0.45333333, ..., -0.32504146,\n",
       "        -0.39130435,  0.09375   ],\n",
       "       [ 0.27187646, -0.14219992, -0.24      , ..., -0.19369818,\n",
       "         1.26086957,  0.9375    ],\n",
       "       [-1.06644829, -0.14889168,  0.58666667, ...,  0.01525705,\n",
       "        -0.2173913 , -0.0625    ],\n",
       "       ..., \n",
       "       [-1.06925597, -0.11375993,  3.21333333, ...,  0.20563847,\n",
       "         0.        ,  0.125     ],\n",
       "       [ 0.1043519 ,  0.32789628,  0.13333333, ..., -0.4358209 ,\n",
       "        -0.30434783, -0.1875    ],\n",
       "       [-0.24754328, -0.33960686, -0.34666667, ...,  2.15655058,\n",
       "         0.26086957,  0.0625    ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def robust_normalize(X):\n",
    "    from sklearn.preprocessing import robust_scale\n",
    "    X = robust_scale(X)\n",
    "    return X\n",
    "X_train,X_test = robust_normalize(X_train),minmax_scale(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Std-mean Scaler*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08758197, -0.1344008 , -0.00178728, ..., -0.21435405,\n",
       "         0.13538382, -0.23239251],\n",
       "       [-0.08980309, -0.6961429 , -0.06246092, ...,  1.05003978,\n",
       "        -0.48204966,  0.43572106],\n",
       "       [-0.03495859, -0.06884538, -0.02345644, ...,  0.3162232 ,\n",
       "        -0.52063925, -0.59877738],\n",
       "       ..., \n",
       "       [-0.03465105,  0.37421881,  0.02180802, ..., -0.49822031,\n",
       "        -0.2891017 , -0.59877738],\n",
       "       [-0.09260511, -0.57181366, -0.02634566, ..., -0.30129738,\n",
       "        -0.40487048,  0.82365797],\n",
       "       [-0.09759408, -1.55966597, -0.06920244, ..., -0.5658429 ,\n",
       "        -1.09948314, -0.57722532]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def st_scaler_sk(X):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit(X).transform(X)\n",
    "    # y_mean = scaler.fit(y_train).mean_\n",
    "    # y_std = np.sqrt(scaler.var_)\n",
    "    return X\n",
    "\n",
    "X_train,X_test = st_scaler_sk(X_train),minmax_scale(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classication\n",
    "### *(In the examples below, I used the std-mean scaler.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier performance\n",
      " ====================\n",
      "Accuracy score:  0.90\n",
      "Precision score:  0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "def rf_clf():\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Random Forest Classifier performance\\n\", \"=\" * 20)\n",
    "    print(f\"Accuracy score: {clf.score(X_test, Y_test): .2f}\")\n",
    "    print(f\"Precision score: {precision_score(Y_test, y_pred): .2f}\")\n",
    "    return y_pred\n",
    "y_pred = rf_clf()\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Guassian Naive Bayesian Classfier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guassian Naive Bayesian Classfier performance\n",
      " ====================\n",
      "Accuracy score:  0.78\n",
      "Precision score:  0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def GNB_clf():\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Guassian Naive Bayesian Classfier performance\\n\", \"=\" * 20)\n",
    "    print(f\"Accuracy score: {clf.score(X_test, Y_test): .2f}\")\n",
    "    print(f\"Precision score: {precision_score(Y_test, y_pred): .2f}\")\n",
    "    return y_pred\n",
    "y_pred = GNB_clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Support Vector Machine Classifer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifer performance\n",
      " ====================\n",
      "Accuracy score:  0.83\n",
      "Precision score:  0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "def SVM_clf():\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Support Vector Machine Classifer performance\\n\", \"=\" * 20)\n",
    "    print(f\"Accuracy score: {clf.score(X_test, Y_test): .2f}\")\n",
    "    print(f\"Precision score: {precision_score(Y_test, y_pred): .2f}\")\n",
    "    return y_pred\n",
    "y_pred = SVM_clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement Suggestions For Andy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *First, I only select some features for the sake of simplicity. You can choose more or less features in the features  in the chose features sector.*\n",
    "### *Second, I directly normalize the entire dataset, which is not a great idea. The thing is, the visual code from finding_donors, is specifically designed for that dataset, and changing it is beyond my ability. It would be great if you could do some feature engineering work for me (such as log some skewed distributed features, etc).*\n",
    "### *Third, I only paired one of the three ways of normalization, which is the std-mean scaler ( for no good reasons), with each classifer. You could do some more pairing later.*\n",
    "### *Fourth, it would be great if you could help with the extraxtion of importance features from these features. I have no idea how to do that because: the importance extraction in finding donors instance can be done easily since they train the dataframe but not the matrix. However, there will be a lot of mishaping bugs or other nonsense bullshit bugs if you train data in the dataframe directly, therefore, in this case, I trained the data in a numpy matrix.*\n",
    "### *Little more in the future, ploting... this is a hard one, and is quite necessary for presentation. And I am having a little bit of trouble to draw fancy graphs...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
